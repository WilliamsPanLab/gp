---
title: "FunctionalEquivalence"
output: github_document
date: "2023-02-10"
---

```{r}
################# ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ 
###  ∆∆∆ Demonstration of functionalEquivalence in bcpa g ~ pcag, p ~ p count, and parentP ~parentP count
################# ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ 
```

```{r}
library(nortest)
# load in masterdf
masterdf=readRDS('~/gp_masterdf.rds')
```

```{r}
# pca prep.
pcVars=c("nihtbx_picvocab_uncorrected","nihtbx_flanker_uncorrected","nihtbx_pattern_uncorrected","nihtbx_picture_uncorrected","nihtbx_reading_uncorrected","pea_ravlt_ld","lmt_scr_perc_correct","pea_wiscv_tss","nihtbx_list_uncorrected","nihtbx_cardsort_uncorrected")
# only pca vars, only timepoint 1 for eval of overlap with bpca
masterdfbv=masterdf[masterdf$eventname=="baseline_year_1_arm_1",]
masterdfbv=masterdfbv[complete.cases(masterdfbv[,pcVars]),]
# and for a pcadf version (pure numeric)
pcaDf<-masterdfbv[complete.cases(masterdfbv[,pcVars]),pcVars]
```

```{r}
################# ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ 
#### G: BPCA ~= PCA
################# ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ 

# compare to thompson PC1
PC1=readRDS('/Users/panlab/Downloads/DEAP-data-download.rds')
PC1$subjectkey=PC1$src_subject_id
PC1$eventname<-PC1$event_name
# only baseline is meaningful
PC1<-PC1[PC1$event_name=='baseline_year_1_arm_1',]

# derive pcs
Y = as.matrix(scale(pcaDf[,pcVars]))
# equiv for binding scores to IDs and eventnames
pcVarsAndIDs=c("nihtbx_picvocab_uncorrected","nihtbx_flanker_uncorrected","nihtbx_pattern_uncorrected","nihtbx_picture_uncorrected","nihtbx_reading_uncorrected","pea_ravlt_ld","lmt_scr_perc_correct","subjectkey","eventname")
Yextended=masterdfbv[,pcVarsAndIDs]
ncomp = 3
y.pca = psych::principal(Y, rotate="varimax", nfactors=ncomp, scores=TRUE)
y.pca$loadings
# assign scores to subjs
Yextended$g<-y.pca$scores[,1]
# merge in cog data
masterdfbv$g<-Yextended$g
# mergin'
compareG_df<-merge(PC1,masterdfbv,by=c('src_subject_id'))
# compare
compareG_df$g<-as.numeric(compareG_df$g)
compareG_df$neurocog_pc1.bl<-as.numeric(compareG_df$neurocog_pc1.bl)
print(cor.test(compareG_df$g,compareG_df$neurocog_pc1.bl))
library(ggplot2)
plotdf<-compareG_df[,c('g','neurocog_pc1.bl')]

y_title <- expression(paste(italic("g")," (pca-derived)"))
x_title <- expression(paste(italic("g")," (bayesian pca-derived)"))

ggplot(data=plotdf,aes(x=g,y=neurocog_pc1.bl))+geom_smooth(method='lm',color='black')+geom_point(alpha=.05)+theme_classic(base_size=30)+ylab(y_title)+xlab(x_title)
### Can add cormat among loadings for all 3 components it looks like they are functionally equivalent all the way down
```

```{r}
################# ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ 
#### P: P FACTOR  ~= SYMPTOM COUNT
################# ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ 
## write a version parallel to michelini et al 2019
### LOAD in cbcl data
cbcl=read.delim('~/Downloads/Package_1205735/abcd_cbcl01.txt')
cbcls=read.delim('/Users/panlab/Downloads/Package_1205735/abcd_cbcls01.txt')
# subset timepoints
cbclsBV=subset(cbcls,eventname=='baseline_year_1_arm_1')
cbcls2=subset(cbcls,eventname=='2_year_follow_up_y_arm_1')
# subset timepoints
cbclBV=subset(cbcl,eventname=='baseline_year_1_arm_1')
cbcl2=subset(cbcl,eventname=='2_year_follow_up_y_arm_1')
# merge with other cbcl
cbclsBV=merge(cbclsBV,cbclBV,by=c('subjectkey','eventname'))
cbcls2=merge(cbcls2,cbcl2,by=c('subjectkey','eventname'))
#### low freq removal
##The following CBCL items were removed because of low frequency: “Drinks alcohol without parents' approval”, “Sexual problems”, “Smokes, chews, or sniffs tobacco”, “Truancy, skips school”, “Uses drugs for non-medical #purposes (don't include alcohol or tobacco)”. 
## find items
lf1<-grep('Drinks alcohol without parents',cbcl[1,])
lf2<-grep('Sexual problem',cbcl[1,])
lf3<-grep('Smokes, chews, or sniffs tobacco',cbcl[1,])
lf4<-grep('Truancy, skips school',cbcl[1,])
lf5<-grep('non medical purpose',cbcl[1,])
# check if these meet criteria in tp2
lf1_nonzero=sum(as.numeric(cbcl2[,lf1])>0)
lf2_nonzero=sum(as.numeric(cbcl2[,lf2])>0)
lf3_nonzero=sum(as.numeric(cbcl2[,lf3])>0)
lf4_nonzero=sum(as.numeric(cbcl2[,lf4])>0)
lf5_nonzero=sum(as.numeric(cbcl2[,lf5])>0)
# add tp1 values
lf1_nonzero=lf1_nonzero+sum(as.numeric(cbclBV[,lf1])>0)
lf2_nonzero=lf2_nonzero+sum(as.numeric(cbclBV[,lf2])>0)
lf3_nonzero=lf3_nonzero+sum(as.numeric(cbclBV[,lf3])>0)
lf4_nonzero=lf4_nonzero+sum(as.numeric(cbclBV[,lf4])>0)
lf5_nonzero=lf5_nonzero+sum(as.numeric(cbclBV[,lf5])>0)

# num rows
numRows=dim(cbcl2)[1]+dim(cbclBV)[1]

# is prop greater 
lf1_nonzero/numRows
lf2_nonzero/numRows
lf3_nonzero/numRows
lf4_nonzero/numRows
lf5_nonzero/numRows

# looks like truancy meets their inclusion criteria with tp2 included

# remove those meeting criteria
cbclBV=cbclBV[-c(lf1,lf2,lf3,lf5)]
cbcl2=cbcl2[-c(lf1,lf2,lf3,lf5)]
# and col names to index later
CBCLcolnames=cbcl[1,]
CBCLcolnames=CBCLcolnames[-c(lf1,lf2,lf3,lf5)]

# polycors to eval if tp1 vars still meet criterion
library(polycor)

# isolate cbcl qs
cbclBV_qs=cbclBV[,10:124]
# fix character specification for variables
cbclBV_qs <- as.data.frame(lapply(cbclBV_qs, as.ordered))
# polycormat
cbclBV_qs_cormat=suppressWarnings(hetcor(cbclBV_qs))
# ok piecemeal go through and find rows with >.75 cors
for (i in 1:dim(cbclBV_qs_cormat$correlations)[1]){
  # 1 is for diagonal
  if (sum(cbclBV_qs_cormat$correlations[i,]>.75)>1){
    print('Correlated Items:')
    # + 9 because 10th col is first col
    print(CBCLcolnames[1,i+9])
    BVoverCorrelateds<-colnames(CBCLcolnames[1,which(cbclBV_qs_cormat$correlations[i,]>.75)+9])
    print(unlist(CBCLcolnames[BVoverCorrelateds]))
    print('-------')
    }
}

#### composite creation
####The following composites were created: Attacks/threatens (“Physically attacks people”, “Threatens people”); Destroys (“Destroys his/her own things”, “Destroys things belonging to his/her family or others”, “Vandalism”); Disobeys rules (“Disobedient at home”, “Disobedient at school”, “Breaks rules at home, school or elsewhere”); Steals (“Steals at home”, “Steals outside ###the home”); Peer problems (“Doesn't get along with other kids”, “Not liked by other kids”); Distracted/Hyperactive (“Can't concentrate, can't pay attention for long”, “Inattentive or easily distracted”, “Can't sit still, restless, or hyperactive”); Hallucinations (“Hears sound or voices that aren't there”, “Sees things that aren't there”); Sex play (“Plays with own sex ###parts in public”, “Plays with own sex parts too much”); Weight problems (“Overeating”, “Overweight”)

# merge timepoints
mergedTPs=cbclBV
# retain subjs and 
mergedTPsSubjs<-mergedTPs$subjectkey
mergedTPsEventName<-mergedTPs$eventname
mergedTPs <- as.data.frame(lapply(mergedTPs, as.numeric))
# inattentive composite
mergedTPs$cbcl_inattentive=round((mergedTPs$cbcl_q08_p+mergedTPs$cbcl_q10_p)/2)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`cbcl_q08_p`,`cbcl_q10_p`))
# aggressive composite
mergedTPs$cbcl_aggresive=round((mergedTPs$cbcl_q16_p+mergedTPs$cbcl_q97_p)/2)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`cbcl_q16_p`,`cbcl_q97_p`))
# anarchic composite
mergedTPs$cbcl_anarchic=round((mergedTPs$cbcl_q22_p+mergedTPs$cbcl_q23_p+mergedTPs$cbcl_q28_p)/3)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`cbcl_q22_p`,`cbcl_q23_p`,`cbcl_q28_p`))
# unpopular composite
mergedTPs$cbcl_unpopular=round((mergedTPs$cbcl_q25_p+mergedTPs$cbcl_q48_p+mergedTPs$cbcl_q38_p)/3)
# remove constits
mergedTPs=subset(mergedTPs, select = -c(`cbcl_q25_p`,`cbcl_q48_p`,`cbcl_q38_p`))
# tummy composite
mergedTPs$cbcl_tummy=round((mergedTPs$cbcl_q56f_p+mergedTPs$cbcl_q56c_p)/2)

####### ∆∆∆∆∆∆∆∆∆∆
## run pca on cbcl
pcaDf_p<-mergedTPs[,10:122]
pcaDf_p$SubjsNames<-mergedTPsSubjs
pcaDf_p$EventNames<-mergedTPsEventName
pcaDf_p=subset(pcaDf_p, select = -c(`eventname`,`timept`,`collection_title`))
# remove NA vars
pcaDf_p_Complete<-pcaDf_p[complete.cases(pcaDf_p),]
pcaDf_p_CompleteSubjs<-pcaDf_p_Complete$SubjsNames
pcaDf_p_CompleteEventNames<-pcaDf_p_Complete$EventNames
# isolate numeric
pcaDf_p_num<-pcaDf_p_Complete[,1:110]
# convert to numeric for pca
pcaDf_p_num <- as.data.frame(lapply(pcaDf_p_num, as.numeric))
# derive pcs
ncomp = 1
y.pca = psych::principal(pcaDf_p_num, rotate="geominT", nfactors=ncomp, scores=TRUE)
y.pca$loadings
# assign scores to subjs
subjPvalues=data.frame(pcaDf_p_CompleteSubjs,pcaDf_p_CompleteEventNames,y.pca$scores[,1])
colnames(subjPvalues)<-c('subjectkey','eventname','p')

# compare 'em
testEquivDf=merge(masterdf,subjPvalues,by=c('subjectkey','eventname'))
print(cor.test(testEquivDf$p,testEquivDf$cbcl_scr_syn_totprob_r))

plotdf<-testEquivDf[,c('p','cbcl_scr_syn_totprob_r')]

# make axix labels
y_title <- expression(paste(italic("p")," (symptom count)"))
x_title <- expression(paste(italic("p")," (pca-derived)"))

ComparePlot<-ggplot(data=plotdf,aes(x=p,y=cbcl_scr_syn_totprob_r))+geom_smooth(method='lm',col='black')+geom_point(alpha=.05)+theme_classic(base_size=30)+ylab(y_title)+xlab(x_title)
ComparePlot
```


```{r}
################# ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ 
#### PARENT P: COUNT ~= FACTOR
################# ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ ∆∆∆ 
### derive adult p
# columns of interest to gauge completeness of
ColsOfInt=asr[,c(11:141)]
# retain complete cases
completeInd=ColsOfInt[rowSums(is.na(ColsOfInt)) == 0,]
ASRcolnames=asr[1,]

### following Micheli approach of composite creation

# polycors to eval if tp1 vars still meet criterion
library(polycor)
# subset asr into timepoints
asrBV=subset(asr,eventname=='baseline_year_1_arm_1')
asr2=subset(asr,eventname=='2_year_follow_up_y_arm_1')

# save subjIDs
asrBVSubjs=asrBV$subjectkey
asr2Subjs=asr2$subjectkey
# isolate asr qs
asrBV_qs=asrBV[,11:141]
asr2_qs=asr2[,11:141]
# fix character specification for variables
asrBV_qs <- as.data.frame(lapply(asrBV_qs, as.ordered))
asr2_qs <- as.data.frame(lapply(asr2_qs, as.ordered))
# polycormat - supress wave of warnings
asrBV_qs_cormat=suppressWarnings(hetcor(asrBV_qs))
asr2_qs_cormat=suppressWarnings(hetcor(asr2_qs))
# ok piecemeal go through and find rows with >.75 cors
for (i in 1:dim(asrBV_qs_cormat$correlations)[1]){
  # a single 1 is expected for diagonal
  if (sum(asrBV_qs_cormat$correlations[i,]>.75)>1){
    # if it is > .75 in both tps
    if (sum(asr2_qs_cormat$correlations[i,]>.75)>1){
      print('Correlated Items:')
      # + 10 because 11th col is first col
      BVoverCorrelateds<-colnames(ASRcolnames[1,which(asrBV_qs_cormat$correlations[i,]>.75)+10])
      year2overCorrelateds<-colnames(ASRcolnames[1,which(asr2_qs_cormat$correlations[i,]>.75)+10])
      intersection=intersect(BVoverCorrelateds,year2overCorrelateds)
      print(unlist(ASRcolnames[intersection]))
      print('-------')
      }
    }
}

#### merge timepoints
mergedTPs=rbind(asrBV_qs,asr2_qs)
# retain subjsIDs and 
mergedTPsSubjs<-c(asrBVSubjs,asr2Subjs)
mergedTPsEventName<-rep()
mergedTPs <- as.data.frame(lapply(mergedTPs, as.numeric))

# destroyer composite
mergedTPs$asr_destroyer=round((mergedTPs$asr_q20_p+mergedTPs$asr_q21_p)/2)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`asr_q20_p`,`asr_q21_p`))

# hallucinations composite
mergedTPs$asr_halluc=round((mergedTPs$asr_q40_p+mergedTPs$asr_q70_p)/2)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`asr_q40_p`,`asr_q70_p`))

# Odd composite
mergedTPs$asr_odd=round((mergedTPs$asr_q84_p+mergedTPs$asr_q85_p)/2)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`asr_q84_p`,`asr_q85_p`))

# sick composite
mergedTPs$asr_sick=round((mergedTPs$asr_q56c_p+mergedTPs$asr_q56g_p)/2)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`asr_q56c_p`,`asr_q56g_p`))

# clumsy composite
mergedTPs$asr_clumsy=round((mergedTPs$asr_q36_p+mergedTPs$asr_q62_p)/2)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`asr_q36_p`,`asr_q62_p`))

# anxious composite
mergedTPs$asr_anx=round((mergedTPs$asr_q45_p+mergedTPs$asr_q50_p)/2)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`asr_q45_p`,`asr_q50_p`))

# swinger composite
mergedTPs$asr_swing=round((mergedTPs$asr_q55_p+mergedTPs$asr_q87_p)/2)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`asr_q55_p`,`asr_q87_p`))

# insolvent composite
mergedTPs$asr_insolvent=round((mergedTPs$asr_q114_p+mergedTPs$asr_q117_p)/2)
# remove constits
mergedTPs=subset(mergedTPs, select = -c(`asr_q114_p`,`asr_q117_p`))
#####################

## run pca on asr
pcaDf_p<-mergedTPs
pcaDf_p$SubjsNames<-mergedTPsSubjs
pcaDf_p$eventname<-c(rep('baseline_year_1_arm_1',dim(asrBV)[1]),rep('2_year_follow_up_y_arm_1',dim(asr2)[1]))
# remove NA vars
pcaDf_p_Complete<-pcaDf_p[complete.cases(pcaDf_p),]
pcaDf_p_CompleteSubjs<-pcaDf_p_Complete$SubjsNames
pcaDf_p_CompleteEventNames<-pcaDf_p_Complete$eventname
pcaDf_p=subset(pcaDf_p, select = -c(`eventname`,`SubjsNames`))
# isolate numeric
pcaDf_p_num<-pcaDf_p_Complete[,1:123]
# convert to numeric for pca
pcaDf_p_num <- as.data.frame(lapply(pcaDf_p_num, as.numeric))
# derive pcs
pcaMat_p_complete = as.matrix(scale(pcaDf_p_num))
ncomp = 1
y.pca = psych::principal(pcaMat_p_complete, rotate="geomin", nfactors=ncomp, scores=TRUE)
y.pca$loadings

subjPvalues=data.frame(pcaDf_p_CompleteSubjs,pcaDf_p_CompleteEventNames,y.pca$scores[,1])
colnames(subjPvalues)<-c('subjectkey','eventname','parentP')

### ∆∆∆ Save out first OutDF
OutDF=merge(masterdf,subjPvalues,by=c('subjectkey','eventname'))
dimOutDF=dim(OutDF)

# exclude subjs without data for both timepoints
OutDFBV=subset(OutDF,eventname=='baseline_year_1_arm_1')
OutDF2Y=subset(OutDF,eventname=='2_year_follow_up_y_arm_1')
# intersection of subjs in both
BothTPsubjs=intersect(OutDFBV$subjectkey,OutDF2Y$subjectkey)
# index out intersection from non tp-split df
OutDF=OutDF[OutDF$subjectkey %in% BothTPsubjs,]
outDf2dim=dim(OutDF)
print(outDf2dim)
dif=dimOutDF[1]-outDf2dim[1]
print(paste0(dif,' rows lost from only using subjs with both timepoints'))

# make count version
ASRdfNum<-as.data.frame(lapply(asr[-1,11:141],as.numeric))
ASRtotal=rowSums(ASRdfNum)
# and subtract reverse score items because they were included in sum above, and modeling "happiness" as symmetric to "symptoms" seems like a strong assumption
# reverse scored = face validity AND loading in expected direction
ASRtotal=ASRtotal-ASRdfNum$asr_q02_p
ASRtotal=ASRtotal-ASRdfNum$asr_q04_p
ASRtotal=ASRtotal-ASRdfNum$asr_q15_p
ASRtotal=ASRtotal-ASRdfNum$asr_q73_p
ASRtotal=ASRtotal-ASRdfNum$asr_q80_p
ASRtotal=ASRtotal-ASRdfNum$asr_q88_p
ASRtotal=ASRtotal-ASRdfNum$asr_q106_p
ASRtotal=ASRtotal-ASRdfNum$asr_q109_p
ASRtotal=ASRtotal-ASRdfNum$asr_q123_p

# merge in (first row is colnames)
asr$parentPcount=c(NA,ASRtotal)
# fix asr age for merge
asr$interview_age=as.numeric(asr$interview_age)/12
# set subjectkey to factor for merge
asr$subjectkey<-as.factor(asr$subjectkey)

# merge
OutDF=merge(OutDF,asr,by=c('subjectkey','eventname','interview_age'))
### confirm tangentivity of sidequest
print(cor.test(OutDF$parentP,OutDF$parentPcount))

plotdf<-OutDF[,c('parentP','parentPcount')]
ComparePlot<-ggplot(data=plotdf,aes(x=parentPcount,y=parentP))+geom_smooth(method='lm',col='black')+geom_point(alpha=.05)+theme_classic()
ComparePlot
```

```{r}
### quick lilliefors test to demonstrate non-normality of psychopathology variables
# BV
lillie.test(OutDFBV$cbcl_scr_syn_totprob_r)
# 2y
lillie.test(OutDF2Y$cbcl_scr_syn_totprob_r)
```
