---
title: "gp_figs"
output: html_document
date: "2022-11-22"
---

```{r}
# libraries
library(mvtnorm)
library(tableone)
library(parallel)
library(rstan)
library(loo)
library(gamm4)
library(Hmisc)
library(FactoMineR)
library(nFactors)
library(reshape2)
library(psych)
library(data.table)
library(mice)
library(abind)
library(cvTools)
library(rapportools)
library(MASS)
library(cowplot)
library(patchwork)
library(gratia)
library(scales)
library(dplyr)
library(data.table)
library(stringr)
library(ggplot2)
# load data
cbcl=read.delim('~/Downloads/Package_1205735/abcd_cbcl01.txt')
nihCog=read.delim('~/Downloads/Package_1206930/abcd_tbss01.txt')
othCog=read.delim('~/Downloads/Package_1206930/abcd_ps01.txt')
littleMan=read.delim('~/Downloads/Package_1206931/lmtp201.txt')
```

```{r}
# organize
# subset timepoints
cbclBV=subset(cbcl,eventname=='baseline_year_1_arm_1')
cbcl2=subset(cbcl,eventname=='2_year_follow_up_y_arm_1')
# nih toolbox
nihCogBV=subset(nihCog,eventname=='baseline_year_1_arm_1')
nihCog2=subset(nihCog,eventname=='2_year_follow_up_y_arm_1')
# other cog
othCogBV=subset(othCog,eventname=='baseline_year_1_arm_1')
othCog2=subset(othCog,eventname=='2_year_follow_up_y_arm_1')
# little man
littleManBV=subset(littleMan,eventname=='baseline_year_1_arm_1')
littleMan2=subset(littleMan,eventname=='2_year_follow_up_y_arm_1')

# for mixed effect modeling
masterdf<-merge(cbcl,nihCog,by=c('subjectkey','eventname','interview_age'))
masterdf<-merge(masterdf,othCog,by=c('subjectkey','eventname','interview_age'))
masterdf<-merge(masterdf,littleMan,by=c('subjectkey','eventname','interview_age'))
```

```{r}
# use thompson 2019 recreation of non nih-tb measures
ind_pea_ravlt = c(which(names(masterdf)=="pea_ravlt_sd_trial_i_tc"),which(names(masterdf)=="pea_ravlt_sd_trial_ii_tc"),
	which(names(masterdf)=="pea_ravlt_sd_trial_iii_tc"),which(names(masterdf)=="pea_ravlt_sd_trial_iv_tc"),
	which(names(masterdf)=="pea_ravlt_sd_trial_v_tc")); names(masterdf)[ind_pea_ravlt];

# set numbers to numeric
masterdf$pea_ravlt_sd_trial_i_tc=as.numeric(masterdf$pea_ravlt_sd_trial_i_tc)
masterdf$pea_ravlt_sd_trial_ii_tc=as.numeric(masterdf$pea_ravlt_sd_trial_ii_tc)
masterdf$pea_ravlt_sd_trial_iii_tc=as.numeric(masterdf$pea_ravlt_sd_trial_iii_tc)
masterdf$pea_ravlt_sd_trial_iv_tc=as.numeric(masterdf$pea_ravlt_sd_trial_vi_tc)
masterdf$pea_ravlt_sd_trial_v_tc=as.numeric(masterdf$pea_ravlt_sd_trial_v_tc)

# total correct across trials
masterdf$pea_ravlt_ld = masterdf$pea_ravlt_sd_trial_i_tc + masterdf$pea_ravlt_sd_trial_ii_tc + masterdf$pea_ravlt_sd_trial_iii_tc + masterdf$pea_ravlt_sd_trial_iv_tc + masterdf$pea_ravlt_sd_trial_v_tc

```

```{r}
#### calculate PCs

# change to numeric
masterdf$nihtbx_picvocab_uncorrected<-as.numeric(masterdf$nihtbx_picvocab_uncorrected)
masterdf$nihtbx_flanker_uncorrected<-as.numeric(masterdf$nihtbx_flanker_uncorrected)
masterdf$nihtbx_list_uncorrected<-as.numeric(masterdf$nihtbx_list_uncorrected)
masterdf$nihtbx_cardsort_uncorrected<-as.numeric(masterdf$nihtbx_cardsort_uncorrected)
masterdf$nihtbx_pattern_uncorrected<-as.numeric(masterdf$nihtbx_pattern_uncorrected)
masterdf$nihtbx_picture_uncorrected<-as.numeric(masterdf$nihtbx_picture_uncorrected)
masterdf$nihtbx_reading_uncorrected<-as.numeric(masterdf$nihtbx_reading_uncorrected)
masterdf$pea_wiscv_tss<-as.numeric(masterdf$pea_wiscv_tss)
masterdf$lmt_scr_perc_correct<-as.numeric(masterdf$lmt_scr_perc_correct)

# isolate PCA df
pcVars=c("nihtbx_picvocab_uncorrected","nihtbx_flanker_uncorrected","nihtbx_pattern_uncorrected","nihtbx_picture_uncorrected","nihtbx_reading_uncorrected","pea_ravlt_ld","lmt_scr_perc_correct")

```

```{r}
# complete other criteria for completeness prior to running pca
# load in additional data
cbcls=read.delim('/Users/panlab/Downloads/Package_1205735/abcd_cbcls01.txt')
# subset timepoints
cbclsBV=subset(cbcls,eventname=='baseline_year_1_arm_1')
cbcls2=subset(cbcls,eventname=='2_year_follow_up_y_arm_1')
#### add non summary items to cbcl for schoolwork q
# subset timepoints
cbclBV=subset(cbcl,eventname=='baseline_year_1_arm_1')
cbcl2=subset(cbcl,eventname=='2_year_follow_up_y_arm_1')
# merge with other cbcl
cbclsBV=merge(cbclsBV,cbclBV,by=c('subjectkey','eventname'))
cbcls2=merge(cbcls2,cbcl2,by=c('subjectkey','eventname'))

# load in clinicalish data
clinc1=read.delim('/Users/panlab/Downloads/Package_1205908/abcd_ksad501.txt')
kBV=subset(clinc1,eventname=='baseline_year_1_arm_1')
k1=subset(clinc1,eventname=='1_year_follow_up_y_arm_1')
k2=subset(clinc1,eventname=='2_year_follow_up_y_arm_1')
clinc1_p=read.delim('/Users/panlab/Downloads/Package_1205908/abcd_ksad01.txt')

# read in grades, annoying distinction between tp1 measure (decent granulrity) and tp2 measure (high granularity)
gradesInfoBV=readRDS('~/Downloads/DEAP-data-download-13.rds')
gradesInfoBV=subset(gradesInfoBV,event_name=='baseline_year_1_arm_1')
gradesInfoBV$Grades<-as.numeric(gradesInfoBV$ksads_back_grades_in_school_p)
gradesInfoBV$Grades[gradesInfoBV$Grades==-1]=NA
gradesInfoBV$eventname=gradesInfoBV$event_name
gradesInfoBV$subjectkey=gradesInfoBV$src_subject_id
# for this one, the key is 1 = A's, 2 = B's, 3 = C's, 4 = D's, 5 = F's, -1 = NA
gradesInfoY2=read.delim('~/Downloads/Package_1207225/abcd_saag01.txt')
gradesInfoY2=subset(gradesInfoY2,eventname=='2_year_follow_up_y_arm_1')
gradesInfoY2$sag_grade_type<-as.numeric(gradesInfoY2$sag_grade_type)
# key: 1=100-97,2=96-93,3=92-90,4=89-87,5=86-83,6=82-80,7=79-77,8=76-73,9=72-70,10=69-67,11=66-65,12=0-65,-1=NA,777= no answer
gradesInfoY2$sag_grade_type[gradesInfoY2$sag_grade_type==-1]=NA
gradesInfoY2$sag_grade_type[gradesInfoY2$sag_grade_type==777]=NA
# now convert to be equivalent with timepoint 1 grades measure
ind12=gradesInfoY2$sag_grade_type==12
ind11=gradesInfoY2$sag_grade_type==11
ind10=gradesInfoY2$sag_grade_type==10
ind9=gradesInfoY2$sag_grade_type==9
ind8=gradesInfoY2$sag_grade_type==8
ind7=gradesInfoY2$sag_grade_type==7
ind6=gradesInfoY2$sag_grade_type==6
ind5=gradesInfoY2$sag_grade_type==5
ind4=gradesInfoY2$sag_grade_type==4
ind3=gradesInfoY2$sag_grade_type==3
ind2=gradesInfoY2$sag_grade_type==2
ind1=gradesInfoY2$sag_grade_type==1
#### Set indices to low-res versions
# < 65 becomes failing
gradesInfoY2$sag_grade_type[ind12]=5
# 66-69 = Ds
gradesInfoY2$sag_grade_type[ind11]=4
gradesInfoY2$sag_grade_type[ind10]=4
# 70-79 = Cs
gradesInfoY2$sag_grade_type[ind7]=3
gradesInfoY2$sag_grade_type[ind8]=3
gradesInfoY2$sag_grade_type[ind9]=3
# 80-89 = Bs
gradesInfoY2$sag_grade_type[ind4]=2
gradesInfoY2$sag_grade_type[ind5]=2
gradesInfoY2$sag_grade_type[ind6]=2
# 90+ = As
gradesInfoY2$sag_grade_type[ind1]=1
gradesInfoY2$sag_grade_type[ind2]=1
gradesInfoY2$sag_grade_type[ind3]=1
gradesInfoY2$Grades<-gradesInfoY2$sag_grade_type
###### ∆∆∆∆∆∆∆ create grades info from both of em
NeededColNames=c('subjectkey','eventname','Grades')
gradesInfo<-rbind(gradesInfoBV[,NeededColNames],gradesInfoY2[,NeededColNames])
gradesInfo$Grades<-as.ordered(gradesInfo$Grades)
###################################

# for mixed effect modeling
masterdf<-merge(cbcls,cbcl,by=c('subjectkey','eventname','interview_age','src_subject_id'))
masterdf<-merge(masterdf,clinc1,by=c('subjectkey','eventname','interview_age','src_subject_id'))
masterdf<-merge(masterdf,clinc1_p,by=c('subjectkey','eventname','interview_age','src_subject_id'))
masterdf<-merge(masterdf,Yextended,by=c('subjectkey','eventname'))

# for within-timepoint measurements
# merge BV
bv=merge(cbclsBV,tbBV,by='subjectkey')
bv=merge(bv,kBV,by='subjectkey')
# merge one year
y1=merge(cbcls1,tb1,by='subjectkey')
y1=merge(y1,k1,by='subjectkey')
# merge two year
y2=merge(cbcls2,tb2,by='subjectkey')
y2=merge(y2,k2,by='subjectkey')
# three year
y3=merge(cbcls3,tb3,by='subjectkey')
y3=merge(y3,k3,by='subjectkey')

#### clean data

# convert to numeric
masterdf$interview_age<-as.numeric(masterdf$interview_age)
# cbcl sum indep. of the q of interest
masterdf$cbcl_scr_syn_totprob_r<-as.numeric(masterdf$cbcl_scr_syn_totprob_r)-as.numeric(masterdf$cbcl_q61_p)
masterdf$cbcl_q61_p<-as.ordered(masterdf$cbcl_q61_p)
masterdf$subjectkey<-as.factor(masterdf$subjectkey)
# save rds out
#### saveRDS(masterdf,'~/subjGvalues_fullcbcl.rds')
# clean data
masterdf$interview_age<-as.numeric(masterdf$interview_age)/12
masterdf$cbcl_scr_syn_totprob_r<-as.numeric(masterdf$cbcl_scr_syn_totprob_r)
masterdf$cbcl_scr_syn_internal_r<-as.numeric(masterdf$cbcl_scr_syn_internal_r)
masterdf$cbcl_scr_syn_external_r<-as.numeric(masterdf$cbcl_scr_syn_external_r)
masterdf$subjectkey<-as.factor(masterdf$subjectkey)
masterdf$cbcl_q61_p<-as.ordered(masterdf$cbcl_q61_p)
# remove instances of NA tot probs
masterdf=masterdf[!is.na(masterdf$cbcl_scr_syn_totprob_r),]
# and for q61
masterdf=masterdf[!is.na(masterdf$cbcl_q61_p),]
# and for is empty
masterdf=masterdf[!is.empty(masterdf$cbcl_scr_syn_totprob_r),]
masterdf=masterdf[!is.empty(masterdf$cbcl_q61_p),]
# r can't take the hint
masterdf=masterdf[!masterdf$cbcl_scr_syn_totprob_r=='',]
masterdf=masterdf[!masterdf$cbcl_q61_p=='',]

```

```{r}
# only use subjects with both timepoints as complete cases
subjs=unique(masterdf$subjectkey)
for (s in subjs){
  # if there are less than two compelte cases of the pca variables
  if (sum(complete.cases(masterdf[masterdf$subjectkey==s,pcVars]))<2){
    subjs=subjs[subjs!=s]
  }
}
# convert masterdf to df with complete observations for cognition
masterdf=masterdf[masterdf$subjectkey %in% subjs,]

```




```{r}
# finish cleaning data for sherlock runs: one family member per family to facilitate random sample
masterdf$id_fam = NULL
# default value of family size (# of children in abcd study)
masterdf$fam_size = 1

# counter index
ind=0

# set each instance of multiple family members to a family ID, as ind
set.seed(1)
for(f in 1:length(unique(masterdf$rel_family_id))){
  # calculate family size
  famsize=sum(masterdf$rel_family_id == unique(masterdf$rel_family_id)[f]) / 2
  masterdf$fam_size[masterdf$rel_family_id == unique(masterdf$rel_family_id)[f]] = famsize
  # note that each  person is represented twice at this point:
  # divide by 2 to take number of visits to number of people, if there's more than 2x visits per family ID, izza family
  # this logic gets hairy. Starting from outside in: > 1 is family size >1, /2 is divided by 2 for two visits, [f] is unique familyID, rel_family_id is place in column of masterdf
  if(famsize>1){
    # remove one from instances where family-id = this relative family id (sequence for siblings, 1:size(Family))
    #print(paste0('family size ',famsize))
    # keep one sib
    kept=sample(seq(1,famsize),1)
    #print(paste0('kept ',kept))
    # use to select one subject id
    famIDs=unique(masterdf$subjectkey[masterdf$rel_family_id == unique(masterdf$rel_family_id)[f]])
    # chosen sib
    keeper=famIDs[kept]
    left=famIDs[-c(kept)]
    # leave rest
    masterdf=masterdf[masterdf$subjectkey!=left,] 
    #print(paste0('left ',left))
    # calc index of family
    ind=ind+1	
    # set index of family
    masterdf$id_fam[masterdf$rel_family_id == unique(masterdf$rel_family_id)[f]] = ind
  }	
}

# make family ID for those with families represented in ABCD
masterdf$rel_family_id=masterdf$id_fam

# pea_wiscv_tss, nihtbx_list_uncorrected, and nihtbx_cardsort_uncorrected taken out for lack of longitudinal coverage
pcaDf<-masterdf[,pcVars]
```

```{r}
# ANALYSIS 0: DERIVE PCS

# derive pcs
Y = as.matrix(scale(pcaDf[complete.cases(pcaDf[,pcVars]),pcVars]))
# equiv for binding scores to IDs and eventnames
pcVarsAndIDs=c("nihtbx_picvocab_uncorrected","nihtbx_flanker_uncorrected","nihtbx_pattern_uncorrected","nihtbx_picture_uncorrected","nihtbx_reading_uncorrected","pea_ravlt_ld","lmt_scr_perc_correct","subjectkey","eventname")
Yextended=masterdf[complete.cases(masterdf[,pcVarsAndIDs]),pcVarsAndIDs]
ncomp = 3
y.pca = psych::principal(Y, rotate="varimax", nfactors=ncomp, scores=TRUE)
y.pca$loadings
# assign scores to subjs
Yextended$g<-y.pca$scores[,1]
# merge in cog data

masterdf$g<-Yextended$g
```


```{r}
#####   # compare to thompson PC1
#####   PC1=readRDS('/Users/panlab/Downloads/DEAP-data-download.rds')
#####   PC1$subjectkey=PC1$src_subject_id
#####   PC1$eventname<-PC1$event_name
#####   # only baseline is meaningful
#####   PC1<-PC1[PC1$event_name=='baseline_year_1_arm_1',]
#####   # mergin'
#####   compareG_df<-merge(PC1,masterdf,by=c('src_subject_id'))
#####   # compare
#####   cor.test(as.numeric(compareG_df$g),compareG_df$neurocog_pc1.bl)
#####   # note: .964 correlation when calculated on only TP1 data
```

```{r}
### PRINOUT BIG DATA FOR CLUSTER BOOTS
gradesMasterdf<-merge(masterdf,gradesInfo,by=c('subjectkey','eventname'))
saveRDS(gradesMasterdf,'~/mixedEfDf_WithGrades.rds')
print(dim(gradesMasterdf))



```

```{r}
# ∆∆∆∆∆∆∆∆∆∆∆∆∆∆
#### 1/25/23 - new analysis 1 - p~g better epxlained by school function
# ∆∆∆∆∆∆∆∆∆∆∆∆∆∆


#### Row 1A - g~p alone
model<-gam(cbcl_scr_syn_totprob_r~s(g)+s(interview_age),data=gradesMasterdf,family = nb())
# plot of p~g
summary(model)
visreg(model,"g",gg=TRUE,ylab="Total Symptoms",scale="response",rug=FALSE,band=FALSE,line.par=list(size=2))+geom_point(alpha=0.01,size=3)+ylim(c(0,170))+theme_minimal(base_size=25)
# note clim 0,170 seems to exclude =< 1% 

### ext
model<-gam(cbcl_scr_syn_external_r~s(g)+s(interview_age),data=gradesMasterdf,family = nb())
# plot of p~g
summary(model)
visreg(model,"g",gg=TRUE,ylab="Externalizing Symptoms",scale="response",rug=FALSE,band=FALSE,line.par=list(size=2))+geom_point(alpha=0.01,size=3)+ylim(c(0,33))+theme_minimal(base_size=25)
# note clim 0,33 seems to exclude =< 1% 

### int
model<-gam(cbcl_scr_syn_internal_r~s(g)+s(interview_age),data=gradesMasterdf,family = nb())
# plot of p~g
summary(model)
visreg(model,"g",gg=TRUE,ylab="Internalizing Symptoms",scale="response",rug=FALSE,band=FALSE,line.par=list(size=2,col='gray'))+geom_point(alpha=0.02,size=3)+ylim(c(0,45))+theme_minimal(base_size=25)
# note clim 0,45 seems to exclude =< 1% 

#### Row 2B - g~p conditional upon school
model<-gam(cbcl_scr_syn_totprob_r~s(g)+s(interview_age)+Grades,data=gradesMasterdf,family = nb())
# plot of p~g
summary(model)
visreg(model,"g",gg=TRUE,ylab="Total Symptoms",scale="response",rug=FALSE,band=FALSE,line.par=list(size=2))+geom_point(alpha=0.01,size=3)+ylim(c(0,170))+theme_minimal(base_size=25)
# note clim 0,170 seems to exclude =< 1% 

### ext
model<-gam(cbcl_scr_syn_external_r~s(g)+s(interview_age)+Grades,data=gradesMasterdf,family = nb())
# plot of p~g
summary(model)
visreg(model,"g",gg=TRUE,ylab="Externalizing Symptoms",scale="response",rug=FALSE,band=FALSE,line.par=list(size=2,col='gray'))+geom_point(alpha=0.01,size=3)+ylim(c(0,33))+theme_minimal(base_size=25)
# note clim 0,33 seems to exclude =< 1% 

### int
model<-gam(cbcl_scr_syn_internal_r~s(g)+s(interview_age)+Grades,data=gradesMasterdf,family = nb())
# plot of p~g
summary(model)
visreg(model,"g",gg=TRUE,ylab="Internalizing Symptoms",scale="response",rug=FALSE,band=FALSE,line.par=list(size=2))+geom_point(alpha=0.02,size=3)+ylim(c(0,45))+theme_minimal(base_size=25)
# note clim 0,45 seems to exclude =< 1% 

### boo-ya all permutations of g~p~grades are high certainty or high uncertainty
```

```{r}
# get equivalent plots for parent P
withParentP<-readRDS('~/OutDfFull.rds')
withParentP$interview_age<-as.numeric(withParentP$interview_age)
#### ∆∆∆∆∆∆∆∆∆∆∆ ##############################


#### p~parentP alone
model<-gam(cbcl_scr_syn_totprob_r~s(interview_age)+s(parentPcount),data=withParentP,family = nb())
# plot of p~g
summary(model)
visreg(model,"parentPcount",gg=TRUE,ylab="Total Symptoms",scale="response",rug=FALSE,band=FALSE,line.par=list(size=2))+geom_point(alpha=0.01,size=3)+ylim(c(0,170))+theme_minimal(base_size=25)
# note clim 0,170 seems to exclude =< 1% 

### ext
model<-gam(cbcl_scr_syn_external_r~s(interview_age)+s(parentPcount),data=withParentP,family = nb())
# plot of p~g
summary(model)
visreg(model,"parentPcount",gg=TRUE,ylab="Externalizing Symptoms",scale="response",rug=FALSE,band=FALSE,line.par=list(size=2))+geom_point(alpha=0.01,size=3)+ylim(c(0,33))+theme_minimal(base_size=25)
# note clim 0,33 seems to exclude =< 1% 

### int
model<-gam(cbcl_scr_syn_internal_r~s(interview_age)+s(parentPcount),data=withParentP,family = nb())
# plot of p~g
summary(model)
visreg(model,"parentPcount",gg=TRUE,ylab="Internalizing Symptoms",scale="response",rug=FALSE,band=FALSE,line.par=list(size=2))+geom_point(alpha=0.02,size=3)+ylim(c(0,45))+theme_minimal(base_size=25)
# note clim 0,45 seems to exclude =< 1% 

#### g~p conditional upon school and parent P
model<-gam(cbcl_scr_syn_totprob_r~s(g)+s(interview_age)+Grades+s(parentPcount),data=withParentP,family = nb())
# plot of p~g
summary(model)
visreg(model,"g",gg=TRUE,ylab="Total Symptoms",scale="response",rug=FALSE,band=FALSE,line.par=list(size=2))+geom_point(alpha=0.01,size=3)+ylim(c(0,170))+theme_minimal(base_size=25)
# note clim 0,170 seems to exclude =< 1% 

### ext
model<-gam(cbcl_scr_syn_external_r~s(g)+s(interview_age)+Grades+s(parentPcount),data=withParentP,family = nb())
# plot of p~g
summary(model)
visreg(model,"g",gg=TRUE,ylab="Externalizing Symptoms",scale="response",rug=FALSE,band=FALSE,line.par=list(size=2))+geom_point(alpha=0.01,size=3)+ylim(c(0,33))+theme_minimal(base_size=25)
# note clim 0,33 seems to exclude =< 1% 

### int
model<-gam(cbcl_scr_syn_internal_r~s(g)+s(interview_age)+Grades+s(parentPcount),data=withParentP,family = nb())
# plot of p~g
summary(model)
visreg(model,"g",gg=TRUE,ylab="Internalizing Symptoms",scale="response",rug=FALSE,band=FALSE,line.par=list(size=2))+geom_point(alpha=0.02,size=3)+ylim(c(0,45))+theme_minimal(base_size=25)
# note clim 0,45 seems to exclude =< 1% 


```


```{r}
### ANALYSIS 1: TEMPORAL PRECEDENCE
# check for timepoint 1 -> 2 prediction for temporal precedence
yearBV=subset(masterdf,eventname=='baseline_year_1_arm_1')
year2=subset(masterdf,eventname=='2_year_follow_up_y_arm_1')

# merge back - .x is tp1, .y is tp2
crossTPdf<-merge(yearBV,year2,by='subjectkey')
crossTPdf$cbcl_scr_syn_totprob_r.x<-as.numeric(crossTPdf$cbcl_scr_syn_totprob_r.x)
crossTPdf$cbcl_scr_syn_totprob_r.y<-as.numeric(crossTPdf$cbcl_scr_syn_totprob_r.y)
# coded as numeric for now
crossTPdf$cbcl_q61_p.x<-as.numeric(crossTPdf$cbcl_q61_p.x)
crossTPdf$cbcl_q61_p.y<-as.numeric(crossTPdf$cbcl_q61_p.y)

# make some gams for predicting timepoint 2 from tp 1 (above and beyond tp1 response variable)
gPredp<-gam(cbcl_scr_syn_totprob_r.y~s(g.x)+s(cbcl_scr_syn_totprob_r.x)+cbcl_q61_p.x,data=crossTPdf,family = nb())
pPredg<-gam(g.y~s(cbcl_scr_syn_totprob_r.x)+s(g.x)+cbcl_q61_p.x,data=crossTPdf)
pPredsc<-gam(cbcl_q61_p.y~s(cbcl_scr_syn_totprob_r.x)+s(g.x)+cbcl_q61_p.x,data=crossTPdf)

# externalizing
gPredp<-gam(cbcl_scr_syn_external_r.y~s(g.x)+s(cbcl_scr_syn_external_r.x)+cbcl_q61_p.x,data=crossTPdf,family = nb())
pPredg<-gam(g.y~s(cbcl_scr_syn_external_r.x)+s(g.x)+cbcl_q61_p.x,data=crossTPdf)
pPredsc<-gam(cbcl_q61_p.y~s(cbcl_scr_syn_external_r.x)+s(g.x)+cbcl_q61_p.x+ti(cbcl_scr_syn_external_r.x,g.x),data=crossTPdf)

# internalizing
gPredp<-gam(cbcl_scr_syn_internal_r.y~s(g.x)+s(cbcl_scr_syn_internal_r.x)+cbcl_q61_p.x,data=crossTPdf,family = nb())
pPredg<-gam(g.y~s(cbcl_scr_syn_internal_r.x)+s(g.x)+cbcl_q61_p.x,data=crossTPdf)
pPredsc<-gam(cbcl_q61_p.y~s(cbcl_scr_syn_internal_r.x)+s(g.x)+cbcl_q61_p.x,data=crossTPdf)

###############################################################
##### ∆∆∆∆∆∆∆∆∆∆∆ with parent P (note DF saved out further down)
###############################################################

withParentP<-readRDS('~/mixedEfDF_wAdultp.rds')
yearBV=subset(withParentP,eventname=='baseline_year_1_arm_1')
year2=subset(withParentP,eventname=='2_year_follow_up_y_arm_1')

# merge back - .x is tp1, .y is tp2
crossTPdf<-merge(yearBV,year2,by='subjectkey')
crossTPdf$cbcl_scr_syn_totprob_r.x<-as.numeric(crossTPdf$cbcl_scr_syn_totprob_r.x)
crossTPdf$cbcl_scr_syn_totprob_r.y<-as.numeric(crossTPdf$cbcl_scr_syn_totprob_r.y)
# coded as numeric for now
crossTPdf$cbcl_q61_p.x<-as.numeric(crossTPdf$cbcl_q61_p.x)
crossTPdf$cbcl_q61_p.y<-as.numeric(crossTPdf$cbcl_q61_p.y)

# make some gams for predicting timepoint 2 from tp 1 (above and beyond tp1 response variable)
gPredp<-gam(cbcl_scr_syn_totprob_r.y~s(g.x)+s(cbcl_scr_syn_totprob_r.x)+cbcl_q61_p.x+s(parentPcount.x),data=crossTPdf,family = nb())
pPredg<-gam(g.y~s(cbcl_scr_syn_totprob_r.x)+s(g.x)+cbcl_q61_p.x+s(parentPcount.x),data=crossTPdf)
pPredsc<-gam(cbcl_q61_p.y~s(cbcl_scr_syn_totprob_r.x)+s(g.x)+cbcl_q61_p.x+s(parentPcount.x),data=crossTPdf)

# externalizing
gPredp<-gam(cbcl_scr_syn_external_r.y~s(g.x)+s(cbcl_scr_syn_external_r.x)+cbcl_q61_p.x+s(parentPcount.x),data=crossTPdf,family = nb())
pPredg<-gam(g.y~s(cbcl_scr_syn_external_r.x)+s(g.x)+cbcl_q61_p.x+s(parentPcount.x),data=crossTPdf)
pPredsc<-gam(cbcl_q61_p.y~s(cbcl_scr_syn_external_r.x)+s(g.x)+cbcl_q61_p.x+s(parentPcount.x),data=crossTPdf)

# internalizing
gPredp<-gam(cbcl_scr_syn_internal_r.y~s(g.x)+s(cbcl_scr_syn_internal_r.x)+cbcl_q61_p.x+s(parentPcount.x),data=crossTPdf,family = nb())
pPredg<-gam(g.y~s(cbcl_scr_syn_internal_r.x)+s(g.x)+cbcl_q61_p.x+s(parentPcount.x),data=crossTPdf)
pPredsc<-gam(cbcl_q61_p.y~s(cbcl_scr_syn_internal_r.x)+s(g.x)+cbcl_q61_p.x+s(parentPcount.x),data=crossTPdf)

# interactions?
gPredp<-gam(cbcl_scr_syn_totprob_r.y~s(g.x)+s(cbcl_scr_syn_totprob_r.x)+cbcl_q61_p.x+s(parentPcount.x)+ti(parentPcount.x,g.x)+ti(parentPcount.x,cbcl_scr_syn_totprob_r.x),data=crossTPdf,family = nb())
gPredp<-gam(cbcl_scr_syn_external_r.y~s(g.x)+s(cbcl_scr_syn_external_r.x)+cbcl_q61_p.x+s(parentPcount.x)+ti(parentPcount.x,g.x)+ti(parentPcount.x,cbcl_scr_syn_external_r.x),data=crossTPdf,family = nb())
gPredp<-gam(cbcl_scr_syn_internal_r.y~s(g.x)+s(cbcl_scr_syn_internal_r.x)+cbcl_q61_p.x+s(parentPcount.x)+ti(parentPcount.x,g.x)+ti(parentPcount.x,cbcl_scr_syn_internal_r.x),data=crossTPdf,family = nb())
```


```{r}
###∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆#
###∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆#
###∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆
# After determining whether or not to use ti() for p, int, and ext, use m=c(2,0) to test for significant non-linearity in the parsed-terms model of each
# gam.predict
fixedEfModel<-gam(g~s(cbcl_scr_syn_totprob_r)+s(interview_age),data=masterdf)
fixedEfModel_Int<-gam(g~s(cbcl_scr_syn_internal_r)+s(interview_age),data=masterdf)
fixedEfModel_Ext<-gam(g~s(cbcl_scr_syn_external_r)+s(interview_age),data=masterdf)
forSpline<-predict(fixedEfModel, data = masterdf)
plotdf<-data.frame(masterdf$cbcl_scr_syn_totprob_r,forSpline,masterdf$g,as.factor(masterdf$eventname))
colnames(plotdf)<-c('totprob','predicted','g','eventname')
# cap at 95th percentile
thePlot<-ggplot(plotdf,aes(totprob,g))+
geom_point(alpha=.1,aes(color=eventname))+
geom_smooth(aes(y=predicted),size=2,se=F,color='black')+
theme_classic(base_size=24)+
xlab('Total Problems Score')+
scale_color_discrete(name="Vist",breaks=c("baseline_year_1_arm_1","2_year_follow_up_y_arm_1"),labels=c("Baseline","2 Years"))+
guides(colour = guide_legend(override.aes = list(alpha = 1)))
library(ggExtra)
ggMarginal(thePlot,groupFill=T)
get_derivs_and_plot(fixedEfModel,smooth='cbcl_scr_syn_totprob_r')
######
###∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆#
###∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆#
###∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆∆#

### ANALYSIS 2: g~p NON-LINEAR (migrated to cluster)

#fixedEfModel<-gam(cbcl_scr_syn_totprob_r~s(g)+s(interview_age)+cbcl_q61_p,data=masterdf,family=nb())
## deviance explained w/o age
#fixedEfModel_full<-gam(cbcl_scr_syn_totprob_r~s(g)+cbcl_q61_p,data=masterdf)
#fixedEfModel_reduced<-gam(cbcl_scr_syn_totprob_r~cbcl_q61_p,data=masterdf)
#fixedEfModel_empty<-gam(cbcl_scr_syn_totprob_r~1,data=masterdf)
#fixedEfModel_reduced_no61<-gam(cbcl_scr_syn_totprob_r~s(g),sp=fixedEfModel_full$sp[1],data=masterdf)
#
### deviance explained
#dev.1<- (deviance(fixedEfModel_reduced)-deviance(fixedEfModel_full))/deviance(fixedEfModel_empty) ## prop expl by s(g)
#dev.2<- (deviance(fixedEfModel_empty)-deviance(fixedEfModel_reduced))/deviance(fixedEfModel_empty) ## prop expl by cbcl61
#
### reduce it the other way...
#dev.2[2]<- (deviance(fixedEfModel_reduced_no61)-deviance(fixedEfModel_full))/deviance(fixedEfModel_empty) ## prop expl by s(x2)
#dev.1[2]<- (deviance(fixedEfModel_empty)-deviance(fixedEfModel_reduced_no61))/deviance(fixedEfModel_empty) # prop expl by s(x1)
#
### average the alternatives
#dev.1 <- mean(dev.1)
#dev.2 <- mean(dev.2)
#
### so now explained deviance adds up...
#dev.1+dev.2
#summary(fixedEfModel_full)$dev.expl

```

```{r}
#### ANALYSIS 3: VARIANCE EXPLAINED W/ + WITHOUT CBCL 61
fixedEfModel<-gam(g~s(cbcl_scr_syn_totprob_r)+s(interview_age),data=masterdf)
deviance_without61<-summary(fixedEfModel)$dev.expl
# model with 61
fixedEfModel<-gam(g~s(interview_age)+s(cbcl_scr_syn_totprob_r)+cbcl_q61_p,data=masterdf)
deviance_with61<-summary(fixedEfModel)$dev.expl
# model without cbcl total
fixedEfModel<-gam(g~s(interview_age)+cbcl_q61_p,data=masterdf)
deviance_withoutTot<-summary(fixedEfModel)$dev.expl
# model with q61 subtracted from cbcl total
masterdf$cbcl_scr_syn_totprob_r_min61<-as.numeric(masterdf$cbcl_scr_syn_totprob_r)-(as.numeric(masterdf$cbcl_q61_p)-1)
fixedEfModel<-gam(g~s(interview_age)+s(cbcl_scr_syn_totprob_r_min61),data=masterdf)
deviance_withTot_sub61<-summary(fixedEfModel)$dev.expl
# barplot
barplot_df<-melt(data.frame(deviance_with61,deviance_withoutTot,deviance_without61,deviance_withTot_sub61))
ggplot(aes(x=variable,y=value),data=barplot_df)+geom_bar(stat='identity')+theme(axis.text.x=element_text(angle=45,vjust=.5))

##### P ∆∆∆∆∆∆∆
# load in bootstrapped data from sherlock
boots<-readRDS('~/Desktop/g_p/DevExplained.rds')
gasResp<-boots[,1:3]
pasResp<-boots[,4:6]

# rename columns - g as response
gasResp$Full<-gasResp[,1]
gasResp$P<-gasResp[,2]
gasResp$School<-gasResp[,3]
gasResp<-gasResp[,4:6]
# melt into plottable df
boot_barplot_df<-melt(gasResp)
# reorder for plot
boot_barplot_df$variable <- factor(boot_barplot_df$variable, levels = c("P", "School", "Full"))
ggplot(aes(x=variable,y=value),data=boot_barplot_df)+geom_boxplot()+theme_classic(base_size=35)+
  ylim(c(0,.15))+
  theme(axis.text.x=element_text(angle=45,vjust=.5))+
  labs(x="Models",y="Variance explained",title = expression(paste(italic("g"))))

# saved out at 700 w 900 h

# rename columns - p as response
pasResp$Full<-pasResp[,1]
pasResp$g<-pasResp[,2]
pasResp$School<-pasResp[,3]
pasResp<-pasResp[,4:6]
# melt into plottable df
boot_barplot_df<-melt(pasResp)
boot_barplot_df$variable <- factor(boot_barplot_df$variable, levels = c("g", "School", "Full"))
ggplot(aes(x=variable,y=value),data=boot_barplot_df)+geom_boxplot()+theme_classic(base_size=35)+ggtitle('P')+
  ylim(c(0,.15))+
  theme(axis.text.x=element_text(angle=45,vjust=.5))+
  labs(x="Models",y="Variance explained")



#### INTERNALIZING ∆∆∆∆∆∆∆
boots<-readRDS('~/Desktop/g_p/DevExplainedInt.rds')
# can sep. into p as response and g as response
gasResp<-boots[,1:3]
pasResp<-boots[,4:6]

# rename columns - g as response
gasResp$Full<-gasResp[,1]
gasResp$Internalizing<-gasResp[,2]
gasResp$School<-gasResp[,3]
gasResp<-gasResp[,4:6]
# melt into plottable df
boot_barplot_df<-melt(gasResp)
# reorder for plot
boot_barplot_df$variable <- factor(boot_barplot_df$variable, levels = c("Internalizing", "School", "Full"))
ggplot(aes(x=variable,y=value),data=boot_barplot_df)+geom_boxplot()+theme_classic(base_size=35)+
  ylim(c(0,.15))+
  theme(axis.text.x=element_text(angle=45,vjust=.5))+
  labs(x="Models",y="Variance explained",title = expression(paste(italic("g"))))

# saved out at 700 w 900 h

# rename columns - p as response
pasResp$Full<-pasResp[,1]
pasResp$g<-pasResp[,2]
pasResp$School<-pasResp[,3]
pasResp<-pasResp[,4:6]
# melt into plottable df
boot_barplot_df<-melt(pasResp)
boot_barplot_df$variable <- factor(boot_barplot_df$variable, levels = c("g", "School", "Full"))
ggplot(aes(x=variable,y=value),data=boot_barplot_df)+geom_boxplot()+theme_classic(base_size=35)+ggtitle('Internalizing')+
  ylim(c(0,.15))+
  theme(axis.text.x=element_text(angle=45,vjust=.5))+
  labs(x="Models",y="Variance explained")

# saved out at 700 w 900 h

#### EXTERNALIZING ∆∆∆∆∆∆
boots<-readRDS('~/Desktop/g_p/DevExplainedExt.rds')

# can sep. into p as response and g as response
gasResp<-boots[,1:3]
pasResp<-boots[,4:6]

# rename columns - g as response
gasResp$Full<-gasResp[,1]
gasResp$Externalizing<-gasResp[,2]
gasResp$School<-gasResp[,3]
gasResp<-gasResp[,4:6]
# melt into plottable df
boot_barplot_df<-melt(gasResp)
# reorder for plot
boot_barplot_df$variable <- factor(boot_barplot_df$variable, levels = c("Externalizing", "School", "Full"))
ggplot(aes(x=variable,y=value),data=boot_barplot_df)+geom_boxplot()+theme_classic(base_size=35)+
  ylim(c(0,.15))+
  theme(axis.text.x=element_text(angle=45,vjust=.5))+
  labs(x="Models",y="Variance explained",title = expression(paste(italic("g"))))


# rename columns - p as response
pasResp$Full<-pasResp[,1]
pasResp$g<-pasResp[,2]
pasResp$School<-pasResp[,3]
pasResp<-pasResp[,4:6]
# melt into plottable df
boot_barplot_df<-melt(pasResp)
boot_barplot_df$variable <- factor(boot_barplot_df$variable, levels = c("g", "School", "Full"))
ggplot(aes(x=variable,y=value),data=boot_barplot_df)+geom_boxplot()+theme_classic(base_size=35)+ggtitle('Externalizing')+
  ylim(c(0,.15))+
  theme(axis.text.x=element_text(angle=45,vjust=.5))+
  labs(x="Models",y="Variance explained")

### update with p as response variable AND correct bootstrapping
```

```{r}
library(pammtools)
#### ANALYSIS 4: TENSOR SMOOTHS WITH AND WITHOUT CONTROLLING FOR SCHOOL PERFORMANCE
fixedEfModel<-gam(g~te(interview_age,cbcl_scr_syn_totprob_r),data=masterdf)
gg_tensor(fixedEfModel)
# individual components to gauge if ti is sig
fixedEfModel<-gam(g~s(interview_age)+s(cbcl_scr_syn_totprob_r)+ti(interview_age,cbcl_scr_syn_totprob_r),data=masterdf)
gg_tensor(fixedEfModel)
# school included
fixedEfModel<-gam(g~te(interview_age,cbcl_scr_syn_totprob_r)+cbcl_q61_p,data=masterdf)
gg_tensor(fixedEfModel)
# individual components for ti()
fixedEfModel<-gam(g~s(interview_age)+s(cbcl_scr_syn_totprob_r)+ti(interview_age,cbcl_scr_syn_totprob_r)+cbcl_q61_p,data=masterdf)
gg_tensor(fixedEfModel)

# internalizing
fixedEfModel<-gam(g~te(interview_age,cbcl_scr_syn_internal_r),data=masterdf)
gg_tensor(fixedEfModel)
# ti components sep.
fixedEfModel<-gam(g~s(interview_age)+s(cbcl_scr_syn_internal_r)+ti(interview_age,cbcl_scr_syn_internal_r),data=masterdf)
# school included
fixedEfModel<-gam(g~te(interview_age,cbcl_scr_syn_internal_r)+cbcl_q61_p,data=masterdf)
gg_tensor(fixedEfModel)
# ti components sep.
fixedEfModel<-gam(g~s(interview_age)+s(cbcl_scr_syn_internal_r)+ti(interview_age,cbcl_scr_syn_internal_r)+cbcl_q61_p,data=masterdf)
gg_tensor(fixedEfModel)


# externalizing components
fixedEfModel<-gam(g~te(interview_age,cbcl_scr_syn_external_r),data=masterdf)
gg_tensor(fixedEfModel)
# ti components sep.
fixedEfModel<-gam(g~s(interview_age)+s(cbcl_scr_syn_external_r)+ti(interview_age,cbcl_scr_syn_external_r),data=masterdf)
# school included
fixedEfModel<-gam(g~te(interview_age,cbcl_scr_syn_external_r)+cbcl_q61_p,data=masterdf)
gg_tensor(fixedEfModel)
# ti components sep.
fixedEfModel<-gam(g~s(interview_age)+s(cbcl_scr_syn_external_r)+ti(interview_age,cbcl_scr_syn_external_r)+cbcl_q61_p,data=masterdf)
gg_tensor(fixedEfModel)


#######################

##### SYMPTOMS AS RESPONSE

#######################

# p factor holistic
fixedEfModel<-gam(cbcl_scr_syn_totprob_r~te(interview_age,g),data=masterdf,family=nb())
gg_tensor(fixedEfModel)
# p factor ti
fixedEfModel<-gam(cbcl_scr_syn_totprob_r~s(interview_age)+s(g)+ti(interview_age,g),data=masterdf,family=nb())
gg_tensor(fixedEfModel)
# p factor holistic + school
fixedEfModel<-gam(cbcl_scr_syn_totprob_r~te(interview_age,g)+cbcl_q61_p,data=masterdf,family=nb())
gg_tensor(fixedEfModel)
# p factor ti + school
fixedEfModel<-gam(cbcl_scr_syn_totprob_r~s(interview_age)+s(g)+ti(interview_age,g)+cbcl_q61_p,data=masterdf,family=nb())
gg_tensor(fixedEfModel)

# internalizing
fixedEfModel<-gam(cbcl_scr_syn_internal_r~te(interview_age,g),data=masterdf,family=nb())
gg_tensor(fixedEfModel)
# int  ti
fixedEfModel<-gam(cbcl_scr_syn_internal_r~s(interview_age)+s(g)+ti(interview_age,g),data=masterdf,family=nb())
gg_tensor(fixedEfModel)
# int  holistic + school
fixedEfModel<-gam(cbcl_scr_syn_internal_r~te(interview_age,g)+cbcl_q61_p,data=masterdf,family=nb())
gg_tensor(fixedEfModel)
# int ti + school
fixedEfModel<-gam(cbcl_scr_syn_internal_r~s(interview_age)+s(g)+ti(interview_age,g)+cbcl_q61_p,data=masterdf,family=nb())
gg_tensor(fixedEfModel)

# externalizing components 
fixedEfModel<-gam(cbcl_scr_syn_external_r~te(interview_age,g),data=masterdf,family=nb())
gg_tensor(fixedEfModel)
# ext ti
fixedEfModel<-gam(cbcl_scr_syn_external_r~s(interview_age)+s(g)+ti(interview_age,g),data=masterdf,family=nb())
# ext holistic + school
fixedEfModel<-gam(cbcl_scr_syn_external_r~te(interview_age,g)+cbcl_q61_p,data=masterdf)
gg_tensor(fixedEfModel)
# ext ti + school
fixedEfModel<-gam(cbcl_scr_syn_external_r~s(interview_age)+s(g)+ti(interview_age,g)+cbcl_q61_p,data=masterdf,family=nb())
gg_tensor(fixedEfModel)

```


```{r}
#### ANALYSIS 5A: KSADS BASELINE 
# loop through ksads questions for timepoint 1
ksadsqs=grep('ksads_',colnames(masterdf))
# initialize p and t vecs
pvector=NULL
tvector=NULL
questionVec=NULL
reporterVec=NULL
# subset to YEAR1
year1df=masterdf[masterdf$eventname=='baseline_year_1_arm_1',]
# loop over ksads questions - CHILD REPORT
for (question in 2:952){
  # get column number
  colNumber=ksadsqs[question]
  # get item number in year1df
  item=colnames(year1df)[colNumber]
  # extract item
  questionAnswers=year1df[,c(item,'g')]
  # subset
  ksadsPos=questionAnswers[questionAnswers[,1]==1,]
  ksadsNeg=questionAnswers[questionAnswers[,1]==0,]
  # dim pos
  dimPos=dim(ksadsPos)
  if (dimPos[1]>1){
    # t-test
    t.testRes=t.test(ksadsPos$g,ksadsNeg$g)
    pvector=c(pvector,t.testRes$p.value)
    tvector=c(tvector,t.testRes$statistic)
    questionVec=c(questionVec,clinc1[1,item])
    reporterVec=c(reporterVec,"Child")
    if (t.testRes$statistic>0 && t.testRes$p.value < 0.01){
      print(item)
      print(t.testRes)
      print(clinc1[1,item])
    }
  }
}

### PARENT REPORT
for (question in 956:1907){
  # get column number
  colNumber=ksadsqs[question]
  # get item number in year1df
  item=colnames(year1df)[colNumber]
  # extract item
  questionAnswers=year1df[,c(item,'g')]
  # subset
  ksadsPos=questionAnswers[questionAnswers[,1]==1,]
  ksadsNeg=questionAnswers[questionAnswers[,1]==0,]
  # dim pos
  dimPos=dim(ksadsPos)
  if (dimPos[1]>1){
    # t-test
    t.testRes=t.test(ksadsPos$g,ksadsNeg$g)
    pvector=c(pvector,t.testRes$p.value)
    tvector=c(tvector,t.testRes$statistic)
    questionVec=c(questionVec,clinc1_p[1,item])
    reporterVec=c(reporterVec,"Parent")
    if (t.testRes$statistic>0 && t.testRes$p.value < 0.01){
      print(item)
      print(t.testRes)
      print(clinc1_p[1,item])
    }
  }
}
```


```{r}
library(ggplot2)
library(forcats)
# plot it
plotdf<-data.frame(pvector,tvector,questionVec,reporterVec)
# fdr correct
plotdf$fdrP<-p.adjust(plotdf$pvector,method='fdr')
sigDf<-plotdf[plotdf$fdrP<0.01,]
# order by t vector
sigDf<-sigDf[order(sigDf$tvector),]
# bar plot
ggplot(aes(fct_reorder(questionVec,tvector),tvector,fill=reporterVec),data=sigDf)+geom_bar(stat = 'identity')+theme(axis.text=element_text(angle=90))+ggtitle('Baseline Visit')
```

```{r}
#### ANALYSIS 5B: KSADS 2 YEAR
# loop through ksads questions for timepoint 1
ksadsqs=grep('ksads_',colnames(masterdf))
# initialize p and t vecs
pvector=NULL
tvector=NULL
questionVec=NULL
reporterVec=NULL
# subset to YEAR1
year2df=masterdf[masterdf$eventname=='2_year_follow_up_y_arm_1',]
# loop over ksads questions - CHILD REPORT
for (question in 2:952){
  # get column number
  colNumber=ksadsqs[question]
  # get item number in year2df
  item=colnames(year2df)[colNumber]
  # extract item
  questionAnswers=year2df[,c(item,'g')]
  # subset
  ksadsPos=questionAnswers[questionAnswers[,1]==1,]
  ksadsNeg=questionAnswers[questionAnswers[,1]==0,]
  # dim pos
  dimPos=dim(ksadsPos)
  if (dimPos[1]>1){
    # t-test
    t.testRes=t.test(ksadsPos$g,ksadsNeg$g)
    pvector=c(pvector,t.testRes$p.value)
    tvector=c(tvector,t.testRes$statistic)
    questionVec=c(questionVec,clinc1[1,item])
    reporterVec=c(reporterVec,"Child")
    if (t.testRes$statistic>0 && t.testRes$p.value < 0.01){
      print(item)
      print(t.testRes)
      print(clinc1[1,item])
    }
  }
}

### PARENT REPORT
for (question in 956:1907){
  # get column number
  colNumber=ksadsqs[question]
  # get item number in year2df
  item=colnames(year2df)[colNumber]
  # extract item
  questionAnswers=year2df[,c(item,'g')]
  # subset
  ksadsPos=questionAnswers[questionAnswers[,1]==1,]
  ksadsNeg=questionAnswers[questionAnswers[,1]==0,]
  # dim pos
  dimPos=dim(ksadsPos)
  if (dimPos[1]>1){
    # t-test
    t.testRes=t.test(ksadsPos$g,ksadsNeg$g)
    pvector=c(pvector,t.testRes$p.value)
    tvector=c(tvector,t.testRes$statistic)
    questionVec=c(questionVec,clinc1_p[1,item])
    reporterVec=c(reporterVec,"Parent")
    if (t.testRes$statistic>0 && t.testRes$p.value < 0.01){
      print(item)
      print(t.testRes)
      print(clinc1_p[1,item])
    }
  }
}

```

```{r}
# plot it
plotdf<-data.frame(pvector,tvector,questionVec,reporterVec)
# fdr correct
plotdf$fdrP<-p.adjust(plotdf$pvector,method='fdr')
sigDf<-plotdf[plotdf$fdrP<0.01,]
# order by t vector
sigDf<-sigDf[order(sigDf$tvector),]
# bar plot
ggplot(aes(fct_reorder(questionVec,tvector),tvector,fill=reporterVec),data=sigDf)+geom_bar(stat = 'identity')+theme(axis.text=element_text(angle=90))+ggtitle('Two-Year Visit')
```


```{r}
#### ANALYSIS 6: ADULT SELF-REPORT
# load in asr
asr=read.delim('~/Downloads/Package_1207917/pasr01.txt',na.strings=c("","NA"))
# columns of interest to gauge completeness of
ColsOfInt=asr[,c(11:141)]
# retain complete cases
completeInd=ColsOfInt[rowSums(is.na(ColsOfInt)) == 0,]
# merge with master
masterdf=merge(asr,masterdf,by=c('subjectkey','eventname','src_subject_id'))
ASRcolnames=asr[1,]

# make permanent record of 
#######MICHELI APPROACH TO FACTOR DELINEATION OF ASR

# composite creation

# polycors to eval if tp1 vars still meet criterion
library(polycor)
# subset asr into timepoints
asrBV=subset(asr,eventname=='baseline_year_1_arm_1')
asr2=subset(asr,eventname=='2_year_follow_up_y_arm_1')

# save subjIDs
asrBVSubjs=asrBV$subjectkey
asr2Subjs=asr2$subjectkey
# isolate asr qs
asrBV_qs=asrBV[,11:141]
asr2_qs=asr2[,11:141]
# fix character specification for variables
asrBV_qs <- as.data.frame(lapply(asrBV_qs, as.ordered))
asr2_qs <- as.data.frame(lapply(asr2_qs, as.ordered))
# polycormat
asrBV_qs_cormat=hetcor(asrBV_qs)
asr2_qs_cormat=hetcor(asr2_qs)
# ok piecemeal go through and find rows with >.75 cors
for (i in 1:dim(asrBV_qs_cormat$correlations)[1]){
  # a single 1 is expected for diagonal
  if (sum(asrBV_qs_cormat$correlations[i,]>.75)>1){
    # if it is > .75 in both tps
    if (sum(asr2_qs_cormat$correlations[i,]>.75)>1){
      print('Correlated Items:')
      # + 10 because 11th col is first col
      BVoverCorrelateds<-colnames(ASRcolnames[1,which(asrBV_qs_cormat$correlations[i,]>.75)+10])
      year2overCorrelateds<-colnames(ASRcolnames[1,which(asr2_qs_cormat$correlations[i,]>.75)+10])
      intersection=intersect(BVoverCorrelateds,year2overCorrelateds)
      print(unlist(ASRcolnames[intersection]))
      print('-------')
      }
    }
}
```

```{r}
#### composite creation
#The following composites were created: Anxious (“I am nervous or tense”, “I am too fearful or anxious”); Destroys (“I damage or destroy my things”, “I damage or destroy things belonging to others”); Attacks/threatens (“I physically attack people”, “I threaten to hurt people”); Money management (“I have trouble managing my money or credit card”, “I fail to pay my debts or meet other financial responsibilities”); Nausea (“Nausea, feel sick”, “Vomiting, throwing up”); Suicidality (“I deliberately try to hurt or kill myself”, “I think about killing myself”); Mood swings (“My moods swing between elation and depression”, “My moods or feeling change suddenly”); Hallucinations (“I hear sounds and voices that other people think aren't there”, “I see things that other people think aren't there”); Oddness (“I do things that other people think are strange”, “I have thoughts that other people would think are strange”); Clumsiness (“I accidentally get hurt a lot, accident-prone”, “I am poorly coordinated or clumsy”)

#### merge timepoints
mergedTPs=rbind(asrBV_qs,asr2_qs)
# retain subjsIDs and 
mergedTPsSubjs<-c(asrBVSubjs,asr2Subjs)
mergedTPsEventName<-rep()
mergedTPs <- as.data.frame(lapply(mergedTPs, as.numeric))

# destroyer composite
mergedTPs$asr_destroyer=round((mergedTPs$asr_q20_p+mergedTPs$asr_q21_p)/2)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`asr_q20_p`,`asr_q21_p`))

# hallucinations composite
mergedTPs$asr_halluc=round((mergedTPs$asr_q40_p+mergedTPs$asr_q70_p)/2)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`asr_q40_p`,`asr_q70_p`))

# Odd composite
mergedTPs$asr_odd=round((mergedTPs$asr_q84_p+mergedTPs$asr_q85_p)/2)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`asr_q84_p`,`asr_q85_p`))

# sick composite
mergedTPs$asr_sick=round((mergedTPs$asr_q56c_p+mergedTPs$asr_q56g_p)/2)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`asr_q56c_p`,`asr_q56g_p`))

# clumsy composite
mergedTPs$asr_clumsy=round((mergedTPs$asr_q36_p+mergedTPs$asr_q62_p)/2)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`asr_q36_p`,`asr_q62_p`))

# anxious composite
mergedTPs$asr_anx=round((mergedTPs$asr_q45_p+mergedTPs$asr_q50_p)/2)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`asr_q45_p`,`asr_q50_p`))

# swinger composite
mergedTPs$asr_swing=round((mergedTPs$asr_q55_p+mergedTPs$asr_q87_p)/2)
# remove constituent variables
mergedTPs=subset(mergedTPs, select = -c(`asr_q55_p`,`asr_q87_p`))

# insolvent composite
mergedTPs$asr_insolvent=round((mergedTPs$asr_q114_p+mergedTPs$asr_q117_p)/2)
# remove constits
mergedTPs=subset(mergedTPs, select = -c(`asr_q114_p`,`asr_q117_p`))
#####################

## run pca on asr
pcaDf_p<-mergedTPs
pcaDf_p$SubjsNames<-mergedTPsSubjs
pcaDf_p$eventname<-c(rep('baseline_year_1_arm_1',dim(asrBV)[1]),rep('2_year_follow_up_y_arm_1',dim(asr2)[1]))
# remove NA vars
pcaDf_p_Complete<-pcaDf_p[complete.cases(pcaDf_p),]
pcaDf_p_CompleteSubjs<-pcaDf_p_Complete$SubjsNames
pcaDf_p_CompleteEventNames<-pcaDf_p_Complete$eventname
pcaDf_p=subset(pcaDf_p, select = -c(`eventname`,`SubjsNames`))
# isolate numeric
pcaDf_p_num<-pcaDf_p_Complete[,1:123]
# convert to numeric for pca
pcaDf_p_num <- as.data.frame(lapply(pcaDf_p_num, as.numeric))
# derive pcs
pcaMat_p_complete = as.matrix(scale(pcaDf_p_num))
ncomp = 1
y.pca = psych::principal(pcaMat_p_complete, rotate="geomin", nfactors=ncomp, scores=TRUE)
y.pca$loadings

subjPvalues=data.frame(pcaDf_p_CompleteSubjs,pcaDf_p_CompleteEventNames,y.pca$scores[,1])
colnames(subjPvalues)<-c('subjectkey','eventname','parentP')

OutDF=merge(masterdf,subjPvalues,by=c('subjectkey','eventname'))
```

```{r}
# make count version
ASRdfNum<-as.data.frame(lapply(asr[-1,11:141],as.numeric))
ASRtotal=rowSums(ASRdfNum)
# and subtract reverse score items because they were included in sum above, and modeling "happiness" as symmetric to "symptoms" seems like a strong assumption
# reverse scored = face validity AND loading in expected direction
ASRtotal=ASRtotal-ASRdfNum$asr_q02_p
ASRtotal=ASRtotal-ASRdfNum$asr_q04_p
ASRtotal=ASRtotal-ASRdfNum$asr_q15_p
ASRtotal=ASRtotal-ASRdfNum$asr_q73_p
ASRtotal=ASRtotal-ASRdfNum$asr_q80_p
ASRtotal=ASRtotal-ASRdfNum$asr_q88_p
ASRtotal=ASRtotal-ASRdfNum$asr_q106_p
ASRtotal=ASRtotal-ASRdfNum$asr_q109_p
ASRtotal=ASRtotal-ASRdfNum$asr_q123_p

# merge in (first row is colnames)
asr$parentPcount=c(NA,ASRtotal)
OutDF=merge(OutDF,asr,by=c('subjectkey','eventname'))
```

```{r}
### FINISHED HERE 
saveRDS(OutDF,'~/mixedEfDF_wAdultp.rds')

# loop through asr questions
asr_qs=grep('asr_',colnames(masterdf))
# initialize p and t vecs
pvector=NULL
tvector=NULL
questionVec=NULL
# loop over asr questions - might want to recode to incorp 124-126
for (question in 2:133){
  # get column number
  colNumber=asr_qs[question]
  # get item number in masterdf
  item=colnames(masterdf)[colNumber]
  # extract item
  questionAnswers=masterdf[,c(item,'g')]
  # subset
  asrPos=questionAnswers[questionAnswers[,1]>0,]
  asrNeg=questionAnswers[questionAnswers[,1]==0,]
  # dim pos
  dimPos=dim(asrPos)
  if (dimPos[1]>1){
    # t-test
    t.testRes=t.test(asrPos$g,asrNeg$g)
    pvector=c(pvector,t.testRes$p.value)
    tvector=c(tvector,t.testRes$statistic)
    # strsplit for dropping .x for indexing OG question name
    item2=strsplit(item,".x")[[1]]
    questionVec=c(questionVec,asr[1,item2])
    if (t.testRes$statistic>0 && t.testRes$p.value < 0.01){
      print(item2)
      print(t.testRes)
      print(asr[1,item2])
    }
  }
}

```

```{r}
library(ggplot2)
library(forcats)
# plot it
plotdf<-data.frame(pvector,tvector,questionVec)
pvector=p.adjust(pvector,method='fdr')
sigDf<-plotdf[plotdf$pvector<0.01,]
# order by t vector
sigDf<-sigDf[order(sigDf$tvector),]
# bar plot
ggplot(aes(fct_reorder(questionVec,tvector),tvector),data=sigDf)+geom_bar(stat = 'identity')+theme(axis.text=element_text(angle=90))
```


```{r}
# load in bootstrapped confidence intervals, plot
parentP=readRDS('~/Desktop/g_p/gparentPPredictedBoots.rds')
# g ~ parentP function
topCI=apply(parentP,2,quantile,c(.99))
bottomCI=apply(parentP,2,quantile,c(.01))
# group variable for plotting
groupVar=rep('Upper',200)
groupVar=c(groupVar,(rep('Lower',200)))
# parentP variable for plotting
parentPVar=c(as.numeric(seq(1,200)),as.numeric(seq(1,200)))
# format df for plotting
CI=c(topCI,bottomCI)
plotdf=data.frame(CI,groupVar,parentPVar)
colnames(plotdf)<-c('CI','groupVar','ParentP')
#  x axis to correct range
plotdf$ParentP<-plotdf$ParentP/(200/max(OutDF$parentPcount))
# plot it
ggplot(aes(x=ParentP,y=CI,group=groupVar),data=plotdf)+geom_line()+geom_hline(yintercept = 0)+ylab('99% CI of Derivative')+xlab('Parent Symptoms')
```
